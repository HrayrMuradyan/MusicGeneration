{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008ab17a-0d1f-4132-89a0-ae0dbbd7a8ef",
   "metadata": {},
   "source": [
    "## Preparing the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0274f711-850f-4ec9-a075-bcec5a639748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from audiocraft.models.loaders import load_lm_model_ckpt, _delete_param, load_compression_model\n",
    "from audiocraft.models.musicgen import MusicGen\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b65c8f-1800-4198-ba7a-54108f1cfc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to trained checkpoint\n",
    "checkpoint_trained = './additional_tools/checkpoints/best_state.th'\n",
    "\n",
    "# Path to musicgen small checkpoint\n",
    "checkpoint_def = 'facebook/musicgen-small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d8b0c-99d3-4bda-ac3b-66e4ddf170c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "cache_dir=None\n",
    "\n",
    "# Make our modification to false\n",
    "memory_saver=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90150425-b28c-4776-9e71-f69edd01328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the config file of the trained checkpoint\n",
    "\n",
    "lm_model_ckpt = load_lm_model_ckpt(checkpoint_trained, cache_dir=cache_dir)\n",
    "cfg = OmegaConf.create(lm_model_ckpt['xp.cfg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f360a-f51e-4502-a256-ebbe68e07a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the config file of the musicgen small checkpoint\n",
    "\n",
    "lm_model_ckpt_def = load_lm_model_ckpt(checkpoint_def, cache_dir=cache_dir)\n",
    "cfg_def = OmegaConf.create(lm_model_ckpt_def['xp.cfg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e35bab-d883-4474-b6a0-8eb01ed2cb01",
   "metadata": {},
   "source": [
    "## Load LM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d3564-bab2-4d74-af40-18d9093daf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting some parameters, declaring the device \n",
    "\n",
    "if cfg.device == 'cpu':\n",
    "    cfg.dtype = 'float32'\n",
    "else:\n",
    "    cfg.dtype = 'float16'\n",
    "cfg.autocast = False\n",
    "\n",
    "# Update the memory saver parameter\n",
    "OmegaConf.update(cfg_def, \"memory_saver.enable\", memory_saver)\n",
    "_delete_param(cfg_def, 'conditioners.self_wav.chroma_stem.cache_path')\n",
    "_delete_param(cfg_def, 'conditioners.args.merge_text_conditions_p')\n",
    "_delete_param(cfg_def, 'conditioners.args.drop_desc_p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c351b-ab34-4a4a-9e13-7b42152c350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiocraft.models.builders import get_lm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4296c65f-499e-483a-97da-43478aa4f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lm model\n",
    "lm_model = get_lm_model(cfg_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d99723-e7ae-468c-9ce1-5c8e611c5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the linear layer weight and bias\n",
    "condition_weight = 'condition_provider.conditioners.description.output_proj.weight'\n",
    "condition_bias = 'condition_provider.conditioners.description.output_proj.bias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80137c3d-7f73-497b-80ff-3c87d3feb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best state of the linear layer (768 -> 1024)\n",
    "lm_model_ckpt['best_state']['model'][condition_weight] = lm_model_ckpt_def['best_state'][condition_weight]\n",
    "lm_model_ckpt['best_state']['model'][condition_bias] = lm_model_ckpt_def['best_state'][condition_bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d8ccd-6b19-48fd-a697-7ca431ad04a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best state of the lm model, switch to eval\n",
    "lm_model.load_state_dict(lm_model_ckpt['best_state']['model'])\n",
    "lm_model.eval()\n",
    "lm_model.cfg = cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9709e-18b2-4fb2-abb5-b78bfde9fa07",
   "metadata": {},
   "source": [
    "## Compression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8f4de4-54df-4bff-bc6a-79dbc68310bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the EnCodec compression model, switch to eval\n",
    "compression_model = load_compression_model(checkpoint_def, device=device)\n",
    "compression_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd3491-cfb1-4ead-ac28-4e03155e7c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A default code from MusicGen\n",
    "if 'self_wav' in lm_model.condition_provider.conditioners:\n",
    "    lm_model.condition_provider.conditioners['self_wav'].match_len_on_eval = True\n",
    "    lm_model.condition_provider.conditioners['self_wav']._use_masking = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e047a-6aea-49a8-96a1-7e4f40b9c118",
   "metadata": {},
   "source": [
    "## MusicGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5087272-d1f7-4e32-afe6-5b85d7371d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate MusicGen class\n",
    "musicgen = MusicGen(checkpoint_def, compression_model, lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4dd2b-9300-4eac-85f7-4c719f788120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set duration of generation in seconds\n",
    "musicgen.set_generation_params(duration=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984b9f9-a744-4458-ab3b-d918e2f3094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(descriptions):\n",
    "    \"\"\"\n",
    "    Given the descriptions as a list, generate music based on the descriptions\n",
    "\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Tokenize the descriptions\n",
    "        tokenized_descr = lm_model.condition_provider.conditioners['description'].tokenize(descriptions)\n",
    "        desc_encoded = lm_model.condition_provider.conditioners['description'](tokenized_descr)\n",
    "    \n",
    "        # Concatenating the encoded description with itself, a trick done by MusicGen (it did with null conditions, but since we do not provide dropout, this is a better way)\n",
    "        desc_encoded = tuple([torch.cat([desc_encoded[i], desc_encoded[i]], dim=0).to(device) for i in range(len(desc_encoded))])\n",
    "       \n",
    "        desc_encoded = {'description': desc_encoded}\n",
    "\n",
    "        # Set generation parameters\n",
    "        generation_params = {\n",
    "                    'use_sampling': cfg.generate.lm.use_sampling,\n",
    "                    'temp': cfg.generate.lm.temp,\n",
    "                    'top_k': cfg.generate.lm.top_k,\n",
    "                    'top_p': cfg.generate.lm.top_p,\n",
    "                }\n",
    "\n",
    "        # Some seeds and compression frame rate (after the encodec)\n",
    "        compression_frame_rate = 50\n",
    "        torch.manual_seed(0)\n",
    "        random.seed(0)\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # Generate the music\n",
    "        with musicgen.autocast:\n",
    "            total_gen_len = musicgen.duration * compression_frame_rate\n",
    "            gen_tokens = musicgen.lm.generate(\n",
    "                None, None, desc_encoded , max_gen_len=total_gen_len,\n",
    "                num_samples=len(descriptions), **generation_params)\n",
    "\n",
    "        # Decode using EnCodec\n",
    "        gen_audio = musicgen.compression_model.decode(gen_tokens, None)\n",
    "    \n",
    "        return gen_audio.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7630523f-1b60-4ea9-8933-4e2264930863",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_descriptions = ['Romantic piano that can be used as Armenian pop music instrumental',\n",
    "                       'Duduk for meditation and relaxing',\n",
    "                       'Violin and piano romantic music for engagement',\n",
    "                       'Armenian dance music with instrument mix',\n",
    "                       'Music similar to Eghishi par',\n",
    "                       'Arno Babajanian style solo piano']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ecfd6-dd4e-4830-a6cb-a461835c558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for description in custom_descriptions:\n",
    "    print(description)\n",
    "    gen_audio = generate([description])\n",
    "    display(Audio(gen_audio[0].numpy(), rate=32000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MusicGen",
   "language": "python",
   "name": "musicgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
