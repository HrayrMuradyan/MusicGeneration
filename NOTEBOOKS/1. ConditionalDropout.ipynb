{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f2527bd-811a-48c2-9ab2-be6f869ee071",
   "metadata": {},
   "source": [
    "# Dataset, DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eb92827-7277-4b17-827e-172c46ecebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import torch\n",
    "from audiocraft.solvers import builders\n",
    "from audiocraft.models.musicgen import MusicGen\n",
    "from audiocraft.environment import AudioCraftEnvironment\n",
    "from audiocraft.utils.utils import get_loader\n",
    "from audiocraft.modules.conditioners import ClassifierFreeGuidanceDropout\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "os.environ[\"AUDIOCRAFT_CONFIG\"] = \"../config/teams/default.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58ae401-6d89-4aa4-a588-741aa6a081e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_raw = {'sample_rate': 32000,\n",
    "       'seed': 2036,\n",
    "       'max_sample_rate': 32000,\n",
    "       'max_channels': 1,\n",
    "        'channels': 1,\n",
    "       'dataset': {'batch_size': 1,\n",
    "                   'num_workers': 10,\n",
    "                   'segment_duration': 30,\n",
    "                   'num_samples': None,\n",
    "                   'return_info': True,\n",
    "                   'shuffle': False,\n",
    "                   'sample_on_duration': False,\n",
    "                   'sample_on_weight': False,\n",
    "                   'min_segment_ratio': 0.8,\n",
    "                   'train': {'num_samples': 1000000, 'shuffle': True},\n",
    "                   'valid': {'num_samples': 10000},\n",
    "                   'evaluate': {'num_samples': 10000},\n",
    "                   'generate': {'num_samples': 50, 'return_info': True, 'batch_size': 1}},\n",
    "       'execute_only': None,\n",
    "       'datasource': {'max_sample_rate': 44100, \n",
    "                      'max_channels': 2, \n",
    "                      'train': '../egs/example_notebook_1',\n",
    "                      'valid': '../egs/example_notebook_1', \n",
    "                      'evaluate': '../egs/example_notebook_1', \n",
    "                      'generate': '../egs/example_notebook_1'},\n",
    "       'optim': {\n",
    "               # 'epochs': 500,\n",
    "                 'updates_per_epoch': 2000,\n",
    "                 # 'lr': 1,\n",
    "                 # 'optimizer': 'dadam',\n",
    "                 # 'adam': {'betas': [0.9, 0.95],\n",
    "                 #          'weight_decay': 0.1,\n",
    "                 #          'eps': 1e-08},\n",
    "                 # 'ema': {'use': True,\n",
    "                 #         'updates': 10,\n",
    "                 #         'device': 'cpu',\n",
    "                 #         'decay': 0.99},\n",
    "                 # 'max_norm': 1.0,\n",
    "                 # 'eager_sync': True\n",
    "                },\n",
    "           'return_info': True\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ec5d60-9c14-4328-ba97-a674cd8fa69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = AttrDict.from_nested_dicts(cfg_raw)\n",
    "cfg = OmegaConf.create(cfg_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6cc9758-6076-4535-abf9-806e2a53eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = builders.get_audio_datasets(cfg, dataset_type=builders.DatasetType.MUSIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5329ffc2-4511-49fb-b685-b176a9032a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x733f2d4d6f50>,\n",
       " 'valid': <torch.utils.data.dataloader.DataLoader at 0x733d8545cc10>,\n",
       " 'evaluate': <torch.utils.data.dataloader.DataLoader at 0x733d85392ad0>,\n",
       " 'generate': <torch.utils.data.dataloader.DataLoader at 0x733d853912a0>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e486cfd-795b-4989-99b3-d3b23cd4fdf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5190684-b9a1-48dc-938a-21c936b2ddaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a3faac-ec0e-4de3-8096-6f003e024473",
   "metadata": {},
   "outputs": [],
   "source": [
    "music, segment_with_attributes = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca8fc1c3-5aed-44a7-8580-0e3cd06774f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MusicInfo(meta=AudioMeta(path='/home/karlos/Documents/workspace/proj/music/MusicGeneration/NOTEBOOKS/../dataset/example/electro_3.wav', duration=180.0, sample_rate=32000, amplitude=None, weight=None, info_path=None), seek_time=99.24656939506531, n_frames=960000, total_frames=960000, sample_rate=32000, channels=1, audio_tokens=None, title='Untitled song', artist='Unknown', key=None, bpm=None, genre='electronic', moods=None, keywords=None, description='Happy Song', name='electro_2', instrument='mix', self_wav=WavCondition(wav=tensor([[[-0.0114, -0.0021,  0.0094,  ..., -0.0494, -0.0476, -0.0621]]]), length=tensor([960000]), sample_rate=[32000], path=['/home/karlos/Documents/workspace/proj/music/MusicGeneration/NOTEBOOKS/../dataset/example/electro_3.wav'], seek_time=[99.24656939506531]), joint_embed={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_with_attributes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "234c552f-ca1c-4d55-a037-82d252e517a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, infos = batch\n",
    "audio_tokens = None\n",
    "assert audio.size(0) == len(infos), (\n",
    "    f\"Mismatch between number of items in audio batch ({audio.size(0)})\",\n",
    "    f\" and in metadata ({len(infos)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1af85d57-8f3f-4a4d-b773-7a80ca489582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MusicInfo(meta=AudioMeta(path='/home/karlos/Documents/workspace/proj/music/MusicGeneration/NOTEBOOKS/../dataset/example/electro_3.wav', duration=180.0, sample_rate=32000, amplitude=None, weight=None, info_path=None), seek_time=99.24656939506531, n_frames=960000, total_frames=960000, sample_rate=32000, channels=1, audio_tokens=None, title='Untitled song', artist='Unknown', key=None, bpm=None, genre='electronic', moods=None, keywords=None, description='This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence ', name='electro_2', instrument='mix', self_wav=WavCondition(wav=tensor([[[-0.0114, -0.0021,  0.0094,  ..., -0.0494, -0.0476, -0.0621]]]), length=tensor([960000]), sample_rate=[32000], path=['/home/karlos/Documents/workspace/proj/music/MusicGeneration/NOTEBOOKS/../dataset/example/electro_3.wav'], seek_time=[99.24656939506531]), joint_embed={})]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos[0].description = 'This is very long sentence '*20\n",
    "infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ae42b330-ee57-48f5-859f-9eb602f985ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConditioningAttributes(text={'meta': AudioMeta(path='/home/karlos/Documents/workspace/proj/music/MusicGeneration/NOTEBOOKS/../dataset/example/electro_3.wav', duration=180.0, sample_rate=32000, amplitude=None, weight=None, info_path=None), 'seek_time': 99.24656939506531, 'n_frames': 960000, 'total_frames': 960000, 'sample_rate': 32000, 'channels': 1, 'audio_tokens': None, 'title': 'Untitled song', 'artist': 'Unknown', 'key': None, 'bpm': None, 'genre': 'electronic', 'moods': None, 'keywords': None, 'description': 'This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence This is very long sentence ', 'name': 'electro_2', 'instrument': 'mix'}, wav={'self_wav': WavCondition(wav=tensor([[[-0.0114, -0.0021,  0.0094,  ..., -0.0494, -0.0476, -0.0621]]]), length=tensor([960000]), sample_rate=[32000], path=['/home/karlos/Documents/workspace/proj/music/MusicGeneration/NOTEBOOKS/../dataset/example/electro_3.wav'], seek_time=[99.24656939506531])}, joint_embed={})]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare attributes\n",
    "attributes = [info.to_condition_attributes() for info in infos]\n",
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "220ff711-eb80-4b4b-83a8-76ba519ee824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConditioningAttributes(text={'meta': None, 'seek_time': None, 'n_frames': None, 'total_frames': None, 'sample_rate': None, 'channels': None, 'audio_tokens': None, 'title': None, 'artist': None, 'key': None, 'bpm': None, 'genre': None, 'moods': None, 'keywords': None, 'description': None, 'name': None, 'instrument': None}, wav={'self_wav': WavCondition(wav=tensor([[[-0.]]]), length=tensor([0]), sample_rate=[32000], path=[None], seek_time=[None])}, joint_embed={})]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_cfg = ClassifierFreeGuidanceDropout(1.0)(attributes)\n",
    "attributes_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a181454b-8782-4e29-9f62-0284c3387816",
   "metadata": {},
   "source": [
    "### Load T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b34965a8-0e21-4a84-9a7a-569509e6bedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karlos/Documents/workspace/venv/music/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "model = MusicGen.get_pretrained('facebook/musicgen-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "88dcea41-1ba5-4897-8c18-fd59635792fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': {'input_ids': tensor([[ 100,   19,  182,  307, 7142,  100,   19,  182,  307, 7142,  100,   19,\n",
       "           182,  307, 7142,  100,   19,  182,  307, 7142,  100,   19,  182,  307,\n",
       "          7142,  100,   19,  182,  307, 7142,  100,   19,  182,  307, 7142,  100,\n",
       "            19,  182,  307, 7142,  100,   19,  182,  307, 7142,  100,   19,  182,\n",
       "           307, 7142,  100,   19,  182,  307,    1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm.condition_provider.tokenize(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a37680eb-f056-4d8f-8fd0-d68289497839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': {'input_ids': tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm.condition_provider.tokenize(attributes_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9ee91648-aca0-48b1-be3b-8921208425a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': (tensor([[[-0., 0., -0.,  ..., -0., -0., 0.],\n",
       "           [-0., 0., -0.,  ..., 0., -0., -0.],\n",
       "           [-0., 0., -0.,  ..., 0., -0., -0.],\n",
       "           ...,\n",
       "           [-0., 0., -0.,  ..., 0., -0., -0.],\n",
       "           [-0., 0., -0.,  ..., 0., -0., -0.],\n",
       "           [-0., 0., -0.,  ..., 0., -0., -0.]]], device='cuda:0',\n",
       "         grad_fn=<MulBackward0>),\n",
       "  tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0]], device='cuda:0'))}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm.condition_provider(model.lm.condition_provider.tokenize(attributes_cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad54dc-50b1-4644-84f1-8f57e1eb3adb",
   "metadata": {},
   "source": [
    "## MAKES ALL DESCRIPTIONS 0 EXCEPT THE FIRST ONE WITH ATTENTION MASK ALL 0s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176804e-a3f3-4d44-8928-e33d96f7bbc6",
   "metadata": {},
   "source": [
    "## WORD DROPOUT BEHAVIOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d7100-2f75-4df0-b252-f8c78a95a31d",
   "metadata": {},
   "source": [
    "words are dropped randomly in original codes. They are just replaced with empty string, so randomly some tokens should be selected and removed with corresponding attention_masks by shifting everything to left "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "2e9ad9da-e8ce-48d7-9138-3d9c4449e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7c0e60a5-c27d-45cb-b00a-d44f357a8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "atts = {'description': \n",
    "            {'input_ids': torch.rand((55, 1024)),\n",
    "             'attention_mask': torch.ones((55), dtype=int)\n",
    "             # 'attention_mask': torch.cat([torch.ones((52), dtype=int), torch.zeros((3), dtype=int)])\n",
    "            }\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "70f74b8c-4a6b-45bf-9fd7-ed56fd6370bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': {'input_ids': tensor([[0.6371, 0.1715, 0.8561,  ..., 0.0298, 0.2770, 0.6483],\n",
       "          [0.5234, 0.3489, 0.8574,  ..., 0.3117, 0.1708, 0.2470],\n",
       "          [0.3904, 0.4157, 0.8487,  ..., 0.5094, 0.7890, 0.9687],\n",
       "          ...,\n",
       "          [0.0982, 0.8166, 0.2535,  ..., 0.8962, 0.9450, 0.4499],\n",
       "          [0.7777, 0.0501, 0.0100,  ..., 0.5549, 0.4836, 0.4864],\n",
       "          [0.5826, 0.7799, 0.2680,  ..., 0.9577, 0.1493, 0.4358]]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1])}}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5eed1c1c-fef8-4862-b823-4530546f399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_description(inp):\n",
    "    \"\"\"\n",
    "    Inplace full dropout.\n",
    "    \"\"\"\n",
    "    inp['description']['input_ids'][...] = 0\n",
    "    inp['description']['attention_mask'][...] = 0\n",
    "    return inp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ab811cd2-dac2-4a16-a535-09f458ebda36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_dropout(inp, index):\n",
    "    \"\"\"\n",
    "    Given input_ids and attention_mask perform token_dropout in given indices.\n",
    "    \"\"\"\n",
    "\n",
    "    inp_ids = inp['description']['input_ids']\n",
    "    attention_mask = inp['description']['attention_mask']\n",
    "    \n",
    "    original_length = attention_mask.shape[0]\n",
    "    \n",
    "    inp_ids[index] = torch.zeros(inp_ids.shape[1], dtype=inp_ids.dtype)\n",
    "    attention_mask[index] = 0\n",
    "    \n",
    "    inp_ids = inp_ids[attention_mask.nonzero(as_tuple=True)]\n",
    "    attention_mask = attention_mask[attention_mask.nonzero(as_tuple=True)]\n",
    "\n",
    "    inp_ids = F.pad(inp_ids, (0, 0, 0, original_length - inp_ids.shape[0]), value = 0.0)\n",
    "    attention_mask = F.pad(attention_mask, (0, original_length - attention_mask.shape[-1]), value = 0)\n",
    "    \n",
    "    inp['description']['input_ids'] = inp_ids\n",
    "    inp['description']['attention_mask'] = attention_mask\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5ce96a52-c613-49dd-ae5b-3f5178a46e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.rand(55) < 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7be4d6ba-6a4d-489c-bda2-95122317946c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False, False, False,  True,  True, False,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True, False, False, False,  True, False,  True, False,\n",
       "        False, False, False, False,  True, False, False, False, False, False,\n",
       "        False,  True, False, False, False])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "035b7e69-0503-4cde-b846-155afffb66fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': {'input_ids': tensor([[0.5234, 0.3489, 0.8574,  ..., 0.3117, 0.1708, 0.2470],\n",
       "          [0.3904, 0.4157, 0.8487,  ..., 0.5094, 0.7890, 0.9687],\n",
       "          [0.2988, 0.4120, 0.6921,  ..., 0.1899, 0.9186, 0.1255],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0])}}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dropout(atts, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4ee5a248-667a-458f-9fd6-bcccc4efce46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': {'input_ids': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       "  'attention_mask': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0])}}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_description(atts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5acbcf-6644-45d7-962d-a90b03bf20e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fad2ff-bc12-4f2c-8093-b55c02e3c19d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "324200bb-06cb-4946-bcc6-32a223f0a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ids = inp['description']['input_ids']\n",
    "attention_mask = inp['description']['attention_mask']\n",
    "\n",
    "original_length = attention_mask.shape[0]\n",
    "\n",
    "inp_ids[index] = torch.zeros(inp_ids.shape[1], dtype=inp_ids.dtype)\n",
    "attention_mask[index] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "643fd0a9-689c-408e-9579-28706e7ed1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5171, 0.8077, 0.6169,  ..., 0.3838, 0.4154, 0.5786],\n",
       "        [0.9120, 0.6587, 0.4010,  ..., 0.0647, 0.3351, 0.0739],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_ids[-15:-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a25ec33f-99ce-452e-9045-359b3d388278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "15884a2b-09ab-40ac-acbd-4aabdd6b8935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9780, 0.4434, 0.2783,  ..., 0.2558, 0.9914, 0.2663],\n",
       "        [0.3825, 0.8021, 0.8806,  ..., 0.3276, 0.3776, 0.0110],\n",
       "        [0.3789, 0.7601, 0.0995,  ..., 0.5196, 0.0649, 0.8234],\n",
       "        ...,\n",
       "        [0.8508, 0.4552, 0.9451,  ..., 0.6921, 0.3860, 0.2226],\n",
       "        [0.5171, 0.8077, 0.6169,  ..., 0.3838, 0.4154, 0.5786],\n",
       "        [0.9120, 0.6587, 0.4010,  ..., 0.0647, 0.3351, 0.0739]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_ids[attention_mask.nonzero(as_tuple=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "598e8d05-39ce-484e-b806-2fdfefbac338",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp_ids = inp_ids[attention_mask.nonzero(as_tuple=True)]\n",
    "attention_mask = attention_mask[attention_mask.nonzero(as_tuple=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "99ca663c-bdf4-4a76-8c03-be74b65ee0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp_ids = F.pad(inp_ids, (0, 0, 0, original_length - inp_ids.shape[0]), value = 0.0)\n",
    "attention_mask = F.pad(attention_mask, (0, original_length - attention_mask.shape[-1]), value = 0)\n",
    "\n",
    "inp['description']['input_ids'] = inp_ids\n",
    "inp['description']['attention_mask'] = attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "020c84a8-0ed8-438c-a11c-fb016c584cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5171, 0.8077, 0.6169,  ..., 0.3838, 0.4154, 0.5786],\n",
       "        [0.9120, 0.6587, 0.4010,  ..., 0.0647, 0.3351, 0.0739],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_ids[-15:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb45a0-ef18-4a5a-abaa-f85a66f73b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382cff72-d704-4243-ae2b-35c3c8aa50ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00de9e-a23f-4c8b-bb0c-3dfdb250e6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8994fd52-604f-4ec3-91eb-743fba8fa7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.rand(55) < 1\n",
    "\n",
    "first_zero_element = (atts['description']['attention_mask'] == 0).nonzero()\n",
    "if len(first_zero_element) > 0:\n",
    "    indices[(atts['description']['attention_mask'] == 0).nonzero()[0].item()-1] = False # Handling Special Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5fd13a08-d54d-4b91-bedc-6e0683c252f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bc11469a-4301-4888-885f-6ff7936ee163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': {'input_ids': tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0]),\n",
       "  'attention_mask': tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0])}}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dropout(atts, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9b1e1538-605b-4327-84ba-9893963cf411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': {'input_ids': tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       "  'attention_mask': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0])}}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_description(atts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecc5b5df-5a5a-4c9d-aee5-34356ea3c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a225bb9b-30d5-4903-b025-298129513bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': {'input_ids': tensor([[ 5574, 11263,     1,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0]], device='cuda:0')}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = deepcopy(model.lm.condition_provider.tokenize(attributes))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcc4765c-ac96-4d88-ab7b-a5a1462651a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 55]), torch.Size([1, 55]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['description']['input_ids'].shape, a['description']['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee7eaa-ce1f-4703-82ab-85f96ccbaf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "de"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
